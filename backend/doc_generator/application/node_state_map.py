"""
This file documents the detailed state updates for each node in the Unified Workflow.

LEGEND:
[FRONTEND] - Content passed directly from the frontend request
[LLM]      - Content generated by an LLM call
[SYSTEM]   - Content computed by system logic/libraries
"""

detailed_node_map = {
    # ==========================================
    # COMMON NODES (Executes for all types)
    # ==========================================
    "common": {
        "validate_sources": {
            "description": "Validates inputs and checks if existing content can be reused from session.",
            "updates": {
                "errors": "[SYSTEM] Validation errors (e.g., no sources provided)",
                "metadata.skip_source_processing": "[SYSTEM] Boolean flag. True if valid content already exists in session (checkpoint hit).",
                "metadata.reused_content": "[SYSTEM] Boolean. True if reusing content from previous run.",
            },
            "frontend_input": {
                "sources": "List of URLs, text, or file IDs from user",
                "output_type": "Target format (pdf, podcast, etc.)",
            },
        },
        "resolve_sources": {
            "description": "Resolves uploaded files to disk paths and normalizes URLs.",
            "updates": {
                "resolved_sources": [
                    {
                        "type": "[SYSTEM] 'file', 'url', or 'text'",
                        "content": "[SYSTEM/FRONTEND] Actual text content or normalized URL",
                        "path": "[SYSTEM] Absolute file path on disk (for uploads)",
                        "original_filename": "[FRONTEND] Original name of uploaded file",
                    }
                ],
                "resolved_file_id": "[SYSTEM] ID of main uploaded file (if single file mode)",
            },
        },
        "extract_sources": {
            "description": "Extracts raw text/content from PDFs, URLs, images, etc.",
            "updates": {
                "content_blocks": [
                    {
                        "type": "[SYSTEM] 'text' or 'image'",
                        "content": "[SYSTEM] Extracted text content",
                        "description": "[LLM] Description of image (if Vision model used)",
                        "source": "[SYSTEM] Origin filename/URL",
                    }
                ],
                "metadata.source_count": "[SYSTEM] Total number of valid sources processed",
            },
        },
        "merge_sources": {
            "description": "Merges all extracted blocks into a single markdown string.",
            "updates": {
                "raw_content": "[SYSTEM] Combined markdown text of all sources. CHECKPOINTED KEY for reuse.",
                "metadata.file_id": "[SYSTEM] File ID for caching purposes",
            },
        },
        "summarize_sources": {
            "description": "Generates a condensed summary of the raw content.",
            "updates": {
                "summary_content": "[LLM] Concise summary of raw_content. Used for context-limited prompts (e.g., image gen, mindmap)."
            },
        },
    },
    # ==========================================
    # DOCUMENT NODES (PDF, PPTX, Markdown)
    # ==========================================
    "document": {
        "doc_detect_format": {
            "description": "Detects input format (mostly for legacy single-file flows).",
            "updates": {
                "input_format": "[SYSTEM] Detected mime-type or extension (e.g., 'application/pdf')"
            },
        },
        "doc_parse_document_content": {
            "description": "Parses specific doc types (redundant with extract_sources but kept for legacy).",
            "updates": {
                # Mostly redundant now, updates same fields as extract/merge in legacy path
                "metadata.num_pages": "[SYSTEM] Page count if PDF",
                "metadata.title": "[SYSTEM] Title from file metadata",
            },
        },
        "doc_transform_content": {
            "description": "Structures raw text into a coherent document with sections.",
            "updates": {
                "structured_content": {
                    "title": "[LLM] Generated document title",
                    "introduction": "[LLM] Intro section",
                    "sections": [
                        {
                            "heading": "[LLM] Section heading",
                            "content": "[LLM] Section body text",
                            "type": "[LLM] 'text', 'list', etc.",
                        }
                    ],
                }
            },
            "frontend_input": {
                "request_data.preferences.audience": "Target audience (e.g., 'expert', 'child')",
                "request_data.preferences.tone": "Writing tone",
            },
        },
        "doc_enhance_content": {
            "description": "Adds executive summaries or slide content if requested.",
            "updates": {
                "enhanced_content": {
                    "executive_summary": "[LLM] High-level summary",
                    "key_takeaways": "[LLM] List of bullet points",
                },
                "structured_content.slides": [
                    {
                        "title": "[LLM] Slide title",
                        "bullets": "[LLM] Slide bullet points",
                        "speaker_notes": "[LLM] Notes for presenter",
                    }
                ],
            },
        },
        "doc_generate_images": {
            "description": "Generates relevant images for document sections.",
            "updates": {
                "structured_content.section_images": [
                    {
                        "section_index": "[SYSTEM] Which section this image belongs to",
                        "prompt": "[LLM] Image generation prompt based on section text",
                        "image_path": "[SYSTEM] Internal mapping to generated image file",
                        "caption": "[LLM] Caption for the image",
                    }
                ]
            },
            "frontend_input": {
                "request_data.preferences.image_style": "Style (e.g., 'minimalist', 'watercolor')"
            },
        },
        "doc_generate_output": {
            "description": "Renders final file (PDF/PPTX) to disk.",
            "updates": {
                "output_path": "[SYSTEM] Absolute path to final generated file",
                "completed": "[SYSTEM] True",
            },
        },
    },
    # ==========================================
    # PODCAST NODES
    # ==========================================
    "podcast": {
        "podcast_generate_script": {
            "description": "Converts content into a dialogue script.",
            "updates": {
                "podcast_script": "[LLM] Full conversation text",
                "podcast_title": "[LLM] Catchy episode title",
                "podcast_dialogue": [
                    {
                        "speaker": "[LLM] 'Host', 'Guest', or specific name",
                        "text": "[LLM] Spoken line",
                    }
                ],
            },
            "frontend_input": {
                "request_data.style": "Podcast style (e.g., 'interview', 'monologue')",
                "request_data.speakers": "List of speaker definitions (names, voices)",
            },
        },
        "podcast_synthesize_audio": {
            "description": "Converts script to Audio (TTS).",
            "updates": {
                "podcast_audio_base64": "[SYSTEM] Base64 encoded MP3/WAV file",
                "podcast_duration_seconds": "[SYSTEM] Length of audio in seconds",
            },
        },
    },
    # ==========================================
    # MINDMAP NODES
    # ==========================================
    "mindmap": {
        "mindmap_generate": {
            "description": "Converts content into a hierarchical tree structure.",
            "updates": {
                "mindmap_tree": {
                    "root": {
                        "label": "[LLM] Central topic",
                        "children": [{"label": "[LLM] Subtopic", "children": []}],
                    }
                }
            },
            "frontend_input": {
                "request_data.mode": "Detail level (e.g., 'summarize', 'detailed')"
            },
        }
    },
    # ==========================================
    # IMAGE NODES
    # ==========================================
    "image": {
        "build_image_prompt": {
            "description": "Creates a detailed image prompt from simple user input or text content.",
            "updates": {
                "image_prompt": "[LLM] Detailed, descriptive prompt optimized for image models"
            },
            "frontend_input": {"request_data.prompt": "User's rough idea (optional)"},
        },
        "image_generate": {
            "description": "Generates visual asset.",
            "updates": {
                "image_data": "[SYSTEM] Base64 encoded image or SVG code",
                "image_prompt_used": "[SYSTEM] The final prompt actually sent to the model",
            },
            "frontend_input": {
                "request_data.style": "Visual style (e.g., 'cyberpunk', 'sketch')"
            },
        },
    },
}
